---
title: Publications
order: 1
---

<div class="d-flex flex-column flex-md-row justify-content-between mb-2">
    <div class="flex-grow-1">
        <h3>Conference Papers</h3>
    </div>
</div>

<div id="paper_scan-semseg" class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <div class="subheading mb-0"><span class="text-primary">Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental Study</span></div>
        <div class="mb-2">IEEE Intelligent Vehicles Symposium (IV) 2020</div>
        <div class="mb-3">Larissa T. Triess, David Peter, Christoph B. Rist, J. Marius Zöllner</div>
        <div class="mb-3">
            Autonomous vehicles need to have a semantic understanding of the three-dimensional world around them in order to reason about their environment.
            State of the art methods use deep neural networks to predict semantic classes for each point in a LiDAR scan.
            A powerful and efficient way to process LiDAR measurements is to use two-dimensional, image- like projections.
            In this work, we perform a comprehensive experimental study of image-based semantic segmentation architectures for LiDAR point clouds.
            We demonstrate various techniques to boost the performance and to improve runtime as well as memory constraints.
        </div>

        <div style="text-align: center;">
            <div class="row mb-5">
                <div class="col row-cols-1">
                    <a href="/assets/img/sections/teaser_scan-semseg_01.svg">
                        <img class="img-fluid img-centered img-zoom mx-auto" src="/assets/img/sections/teaser_scan-semseg_01.svg" alt="icon-networksize"/>
                    </a>
                </div>
                <div class="col row-cols-1">
                    <a href="/assets/img/sections/teaser_scan-semseg_02.svg">
                        <img class="img-fluid img-centered img-zoom mx-auto" src="/assets/img/sections/teaser_scan-semseg_02.svg" alt="icon-scanunfolding"/>
                    </a>
                </div>
                <div class="col row-cols-1">
                    <a href="/assets/img/sections/teaser_scan-semseg_03.svg">
                        <img class="img-fluid img-centered img-zoom mx-auto" src="/assets/img/sections/teaser_scan-semseg_03.svg" alt="icon-lossfunction"/>
                    </a>
                </div>
                <div class="col row-cols-1">
                    <a href="/assets/img/sections/teaser_scan-semseg_04.svg">
                        <img class="img-fluid img-centered img-zoom mx-auto" src="/assets/img/sections/teaser_scan-semseg_04.svg" alt="icon-slc"/>
                    </a>
                </div>
            </div>
        </div>

        <a target=_blank href=https://arxiv.org/pdf/2004.11803.pdf class="btn btn-dark"><i class="fas fa-file-pdf" aria-hidden=true></i>&nbsp;pdf</a>
        <a target=_blank href=https://larissa.triess.eu/scan-semseg class="btn btn-light"><i class="fa fa-rocket" aria-hidden=true></i>&nbsp;project</a>
        <a target=_blank href=https://larissa.triess.eu/scan-semseg#code class="btn btn-light"><i class="fa fa-code" aria-hidden=true></i>&nbsp;code</a>
        <button class="btn btn-light" onclick="document.getElementById('idtriess2020arxiv').style.display='block'"><i class="fa fa-quote-left" aria-hidden=true></i>&nbsp;cite</button>
        <div id="idtriess2020arxiv" class="modal">
            <div class="modal-dialog-centered">
                <div class="modal-content">
                    <p id="bibtex_triess2020arxiv">
                        @article{triess2020arxiv,<br>
                            &emsp;title={Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental Study},<br>
                            &emsp;author={Triess, Larissa T. and Peter, David and Rist, Christoph B. and Z\"ollner, J. Marius},<br>
                            &emsp;journal={arxiv},<br>
                            &emsp;year={2020}<br>
                        }
                    </p>

                    <div style="text-align: center;">
                        <div class="row">
                            <div class="col row-cols-1">
                                <button class="btn btn-outline-primary" style="width: 100%;" onclick="copyToClipboard('#bibtex_triess2020arxiv')"><i class="far fa-copy"></i>&nbsp;copy</button>
                            </div>
                            <div class="col row-cols-1">
                                <button class="btn btn-outline-dark" style="width: 100%;" onclick="document.getElementById('idtriess2020arxiv').style.display='none'"><i class="fas fa-times"></i>&nbsp;close</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<div id="paper_pc-upsampling" class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <div class="subheading mb-0"><span class="text-primary">CNN-based synthesis of realistic high-resolution LiDAR data</span></div>
        <div class="mb-2">IEEE Intelligent Vehicles Symposium (IV) 2019</div>
        <div class="mb-3">Larissa T. Triess, David Peter, Christoph B. Rist, Markus Enzweiler, J. Marius Zöllner</div>
        <div class="mb-3">
            This paper presents a novel CNN-based approach for synthesizing high-resolution LiDAR point cloud data.
            Our approach generates semantically and perceptually realistic results with guidance from specialized loss-functions.
            First, we utilize a modified per-point loss that addresses missing LiDAR point measurements.
            Second, we align the quality of our generated output with real-world sensor data by applying a perceptual loss.
            <br>
            In large-scale experiments on real-world datasets, we evaluate both the geometric accuracy and semantic segmentation performance using our generated data vs. ground truth.
            In a mean opinion score testing we further assess the perceptual quality of our generated point clouds.
            Our results demonstrate a significant quantitative and qualitative improvement in both geometry and semantics over traditional non CNN-based up-sampling methods
        </div>

        <a href="/assets/img/sections/teaser_pc-upsampling.png">
            <div class="mb-5"><img class="img-fluid img-centered img-zoom mx-auto mb-2" src="/assets/img/sections/teaser_pc-upsampling.png" alt="" /></div>
        </a>

        <a target=_blank href=https://arxiv.org/pdf/1907.00787.pdf class="btn btn-dark"><i class="fas fa-file-pdf" aria-hidden=true></i>&nbsp;pdf</a>
        <a target=_blank href="/assets/pdf/triess2019iv_poster.pdf" class="btn btn-light"><i class="fas fa-map" aria-hidden=true></i>&nbsp;poster</a>
        <a target=_blank href=https://larissa.triess.eu/pc-upsampling class="btn btn-light"><i class="fa fa-rocket" aria-hidden=true></i>&nbsp;project</a>
        <button class="btn btn-light" onclick="document.getElementById('idtriess2019iv').style.display='block'"><i class="fa fa-quote-left" aria-hidden=true></i>&nbsp;cite</button>
        <div id="idtriess2019iv" class="modal">
            <div class="modal-dialog-centered">
                <div class="modal-content">
                    <p id="bibtex_triess2019iv">
                        @inproceedings{triess2019iv,<br>
                            &emsp;author={Triess, Larissa T. and Peter, David and Rist, Christoph B. and Enzweiler, Markus and Z\"ollner, J. Marius},<br>
                            &emsp;booktitle={2019 IEEE Intelligent Vehicles Symposium (IV)},<br>
                            &emsp;title={CNN-based synthesis of realistic high-resolution LiDAR data},<br>
                            &emsp;year={2019},<br>
                            &emsp;pages={1512-1519},<br>
                        }
                    </p>
                    <div style="text-align: center;">
                        <div class="row">
                            <div class="col row-cols-1">
                                <button class="btn btn-outline-primary" style="width: 100%;" onclick="copyToClipboard('#bibtex_triess2019iv')"><i class="far fa-copy"></i>&nbsp;copy</button>
                            </div>
                            <div class="col row-cols-1">
                                <button class="btn btn-outline-dark" style="width: 100%;" onclick="document.getElementById('idtriess2019iv').style.display='none'"><i class="fas fa-times"></i>&nbsp;close</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<div class="d-flex flex-column flex-md-row justify-content-between mb-2">
    <div class="flex-grow-1">
        <h3>Patents</h3>
    </div>
</div>

<div class="d-flex flex-column flex-md-row justify-content-between mb-2">
    <div class="flex-grow-1">
        <div class="subheading mb-0"><a href="https://patents.google.com/patent/DE102019003621A1">DE102019003621A1</a></div>
        <div>Triess, Larissa; Peter, David. 2020. Verfahren zur Verarbeitung von Lidarsensordaten.</div>
        <div>German Patent DE102019003621A1, filed 23.05.2019, issued 02.01.2020.</div>
    </div>
</div>

<div class="d-flex flex-column flex-md-row justify-content-between">
    <div class="flex-grow-1">
        <div class="subheading mb-0"><a href="https://patents.google.com/patent/DE102020001541A1">DE102020001541A1</a></div>
        <div>Triess, Larissa. 2020. Method for transforming acquired sensor data from a first data domain into a second data domain.</div>
        <div>German Patent DE102020001541A1, filed 09.03.2020. issued 01.10.2020.</div>
    </div>
</div>
